{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read from sample annotations and vcf files\n",
    "sample_annot_deli = ',' #'\\t' for tsv and ',' for csv\n",
    "sample_annot_file_list = ['sample_input/hipster.csv']\n",
    "\n",
    "mt_file_type = 'vcf' # support 'vcf' or 'plink'\n",
    "mt_file_list = ['sample_input/S1.vcf.bgz',\n",
    "             'sample_input/S2.vcf.bgz']\n",
    "\n",
    "## or for plink files (bed bim fam), provide prefix only\n",
    "#mt_file_list = ['paths/to/plink-1',\n",
    "#             'paths/to/plink-2']\n",
    "mt_merge_type = 'sample' # 'variant' for different variants in different files, 'sample' for same variants in different files\n",
    "\n",
    "analysis_name = 'merge_sample'\n",
    "\n",
    "downsample_percent = 0.01 # ratio of variants to be selected (randomly) for QC plots\n",
    "graph_type = 'stack' # or 'group': representation when 2 variables are plotted at the same time\n",
    "fields_to_plot = ['isFemale', 'Population', 'isCase'] # list of fields in sample annotations for QC plotting\n",
    "\n",
    "n_factor = 4 # number of factors for PCA\n",
    "\n",
    "## variant-spark\n",
    "PATH_TO_VS = '~/VariantSpark/bin/variant-spark' #full path to where variant-spark is installed (included in the package)\n",
    "mtry_fraction=0.1\n",
    "num_of_tree=1000\n",
    "\n",
    "## Some configs\n",
    "numCPU = 16\n",
    "memory = '100g'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Environment init\n",
    "\n",
    "import os\n",
    "pyspark_submit_args = ' --driver-memory ' + memory + ' pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "\n",
    "import hail as hl\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, FactorRange, LabelSet, Label\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models.mappers import CategoricalColorMapper\n",
    "\n",
    "from pprint import pprint\n",
    "#output_notebook()\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import math as math\n",
    "import sys\n",
    "import operator\n",
    "from collections import OrderedDict\n",
    "import subprocess\n",
    "from itertools import cycle\n",
    "import shutil\n",
    "\n",
    "\n",
    "hl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = re.sub(r'\\s','_',analysis_name)\n",
    "cwd = os.getcwd()\n",
    "result_dir = cwd + '/' +result_dir\n",
    "numPartitions = numCPU*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop around fileds and generate graph for each field\n",
    "#  get rows field count, names, types\n",
    "## INPUT: table \n",
    "## OUTPUT: col_count(int), col_names(list<str>), col_types(list<str>)\n",
    "def get_table_fields(t):\n",
    "    col_names = list(t.row.dtype.keys())\n",
    "    col_types = list(t.row.dtype.values())\n",
    "    col_types = [str(w).replace('dtype', '') for w in col_types]\n",
    "    col_dict = dict(zip(col_names,col_types))\n",
    "    return(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save plot in a html file\n",
    "## and write a plot division with proper headings in html\n",
    "## INPUT: bokeh figure object p, filename_to_save(str), folder_to_save(str), id for the division in html(str)\n",
    "## OUTPUT: division html(str)\n",
    "def save_plot(p, title, folder, id_link):\n",
    "    html = file_html(p, CDN, title)\n",
    "    filepath = 'plots/'+folder+'/'+title+'.html'\n",
    "    directory = os.path.dirname(filepath)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    f = open(filepath, \"w+\")\n",
    "    f.write(html)\n",
    "    f.close()\n",
    "    plot_html = \"<div>\\n<h3 id='\" + id_link + \"' class='w3-text-teal'>\" + title + \"</h3>\\n\"\n",
    "    plot_html = plot_html + '<object width=\"100%\" height=\"' + str(p.plot_height+100) + '\" data=\"../'+filepath+'\"></object>\\n'\n",
    "    plot_html = plot_html + \"</div>\\n<br><br>\\n\"\n",
    "    return(plot_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given a float/int field in rows/cols table\n",
    "## generate a histogram of the field with specified downsample percent\n",
    "## INPUT: matrixtable, field(expression), field_name(str), downsample_percent(float), analyse_name\n",
    "## OUTPUT: bokeh plot\n",
    "def get_hist_graph(mt, field, field_name, downsample_percent, isVariant, analyse_name):\n",
    "    title=field_name + ' Histogram'\n",
    "    id_link = analyse_name + '-' + field_name\n",
    "    \n",
    "    if isVariant:\n",
    "        stats = mt.aggregate_rows(hl.expr.aggregators.stats(field))\n",
    "        if stats == None:\n",
    "            plot_html = \"<div>\\n<h3 id='\" + id_link + \"' class='w3-text-teal'>\" + title + \"</h3>\\n\"\n",
    "            plot_html = plot_html + '<p> divisor equals 0 exist. Unable to generate a histogram with NA values </p><br>'\n",
    "            plot_html = plot_html + \"</div>\\n<br><br>\\n\"\n",
    "            return(plot_html)\n",
    "        unique_count = len(mt.aggregate_rows(hl.expr.aggregators.counter(field)))\n",
    "        hist = mt.aggregate_rows(hl.expr.aggregators.hist(field,stats.min-1,stats.max+1,int(unique_count*downsample_percent)+1))\n",
    "    else:\n",
    "        stats = mt.aggregate_cols(hl.expr.aggregators.stats(field))\n",
    "        if stats == None:\n",
    "            plot_html = \"<div>\\n<h3 id='\" + id_link + \"' class='w3-text-teal'>\" + title + \"</h3>\\n\"\n",
    "            plot_html = plot_html + '<p> divisor equals 0 exist. Unable to generate a histogram with NA values </p><br>'\n",
    "            plot_html = plot_html + \"</div>\\n<br><br>\\n\"\n",
    "            return(plot_html)\n",
    "        unique_count = len(mt.aggregate_cols(hl.expr.aggregators.counter(field)))\n",
    "        hist = mt.aggregate_cols(hl.expr.aggregators.hist(field,stats.min-1,stats.max+1,int(unique_count*downsample_percent)+1))\n",
    "    \n",
    "    p = hl.plot.histogram(hist, legend=field_name, title=title)\n",
    "    print(title)\n",
    "    return(save_plot(p, title,analyse_name, id_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get unique value counts of given field\n",
    "def get_unique_values(mt, field, isVariant):\n",
    "    if isVariant:\n",
    "        unique_values = mt.aggregate_rows(hl.expr.aggregators.counter(field))\n",
    "    else:    \n",
    "        unique_values = mt.aggregate_cols(hl.expr.aggregators.counter(field))\n",
    "\n",
    "    return unique_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given a matrixtable and a row/col field\n",
    "## find if the field is categorical or not\n",
    "def isCat(mt, field, isVariant):\n",
    "    unique_count = len(get_unique_values(mt, field, isVariant))\n",
    "    if unique_count <= 10:\n",
    "        isCat = True\n",
    "    else:\n",
    "        isCat = False\n",
    "    \n",
    "    return isCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given a matrix table and a field\n",
    "## produce a bar graph of the field\n",
    "## INPUT: matrixtable, field<expression>, field_name<str>, isVariant<boolean>, analyse_name<str>\n",
    "## OUTPUT: bargraph p\n",
    "def get_bar_graph(mt, field, field_name, isVariant, analyse_name):\n",
    "    legend = field_name\n",
    "    title = legend + ' bar graph'\n",
    "    width = 0.5\n",
    "    \n",
    "    unique_values = get_unique_values(mt,field, isVariant)\n",
    "    top_list = list(unique_values.values())\n",
    "    x_co_names = [ str(i) for i in list(unique_values.keys())]\n",
    "    \n",
    "    source = ColumnDataSource(data=dict(x_names = x_co_names, tops = top_list))\n",
    "    p = figure(title=title, x_range = x_co_names, x_axis_label=legend, y_axis_label='Frequency', background_fill_color='#EEEEEE',\n",
    "              tooltips=\"@x_names: @tops\", plot_height =600)\n",
    "    p.vbar(\n",
    "        x = 'x_names', width=width, top='tops', bottom=0, source=source)\n",
    "    id_link = analyse_name + '-' +field_name\n",
    "    #show(p)\n",
    "    return(save_plot(p, title,analyse_name,id_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for get_bar_graph_A_by_B\n",
    "## get top values for combo keys\n",
    "## add 0 to non-exist entries\n",
    "## INPUT: A_values(list), filtered matrix table, selected filtered fieldA(expr), cols/rows(boolean)\n",
    "def get_top_values(A_values,mt_filtered, field_filtered, isVariant):\n",
    "    tops = get_unique_values(mt_filtered, field_filtered, isVariant)\n",
    "    for a in A_values:\n",
    "        if a not in tops.keys():\n",
    "            tops[a] = 0\n",
    "    return [tops[a] for a in A_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for get_bar_graph_A_by_B\n",
    "## map data from multi series into one tuple orderly\n",
    "## for grouped bar graph input\n",
    "## INPUT:  counts of each combo keyed by A_values(dict)\n",
    "## OUTPUT: A tuple of counts ordered by x (combo key variable)\n",
    "def map_counts(tops):\n",
    "    counts = []\n",
    "    index = 0\n",
    "    key_names = list(tops.keys())\n",
    "    while index < len(tops[key_names[0]]):\n",
    "        list_to_append = [tops[a][index]for a in key_names]\n",
    "        counts.extend(list_to_append)\n",
    "        index = index + 1\n",
    "    counts = tuple(counts)\n",
    "    \n",
    "    return(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get A grouped by B\n",
    "## INPUT: matrixtable, field_names(list<str>) [A,B](full name after mt), graph_type(str) :group or stack, analyse_name(str)\n",
    "## OUTPUT: a bar graph of A by B\n",
    "def get_bar_graph_A_by_B(mt, field_names, graph_type, analyse_name):\n",
    "    width = 0.5\n",
    "    palette = d3['Category10'][10]\n",
    "    # get field names and unique values\n",
    "    name_indexes = [ field_name.split('.') for field_name in field_names]\n",
    "    field_values = [list(get_unique_values(mt,mt[name[0]][name[1]],False).keys()) for name in name_indexes]\n",
    "    title = name_indexes[0][1] + ' by ' + name_indexes[1][1]\n",
    "    id_link = analyse_name + '-' + name_indexes[0][1] + 'by' + name_indexes[1][1]\n",
    "    # get filter data and feed into top\n",
    "    tops = {}\n",
    "    for v in field_values[1]:\n",
    "        mt_filtered = mt.filter_cols(mt[name_indexes[1][0]][name_indexes[1][1]] == v, keep=True)\n",
    "        field_filtered = mt_filtered[name_indexes[0][0]][name_indexes[0][1]]\n",
    "        tops[str(v)] = list(get_top_values(field_values[0], mt_filtered, field_filtered, False))\n",
    "    # string type everything\n",
    "    field_values[0] = [str(x) for x in field_values[0]]\n",
    "    field_values[1] = [str(x) for x in field_values[1]]\n",
    "    \n",
    "    if graph_type == 'group':\n",
    "        # format and map data\n",
    "        x = [(str(fn1), str(fn2)) for fn1 in field_values[0] for fn2 in field_values[1]]\n",
    "        counts = map_counts(tops)\n",
    "        labels = [ str(fn2) for fn1 in field_values[0] for fn2 in field_values[1]]\n",
    "        source = ColumnDataSource(data=dict(x=x, counts=counts,labels= labels))\n",
    "\n",
    "        p = figure(x_range = FactorRange(*x), plot_height=600, title=title, tooltips=\"@x: @counts\")\n",
    "\n",
    "        p.vbar(x='x', top='counts', width=0.9, source=source,\n",
    "               fill_color=factor_cmap('x', \n",
    "                                      palette=palette, \n",
    "                                      factors=[str(value) for value in field_values[1]],\n",
    "                                      start=1, end=2),\n",
    "                legend='labels')\n",
    "    elif graph_type == 'stack':\n",
    "        data = {'A_values': field_values[0]}\n",
    "        data.update(tops)\n",
    "        source = ColumnDataSource(data)\n",
    "        colors = palette[0:len(field_values[1])]\n",
    "        print(field_values[0])\n",
    "        p = figure(x_range=field_values[0], plot_height=600, title=title,\n",
    "                  toolbar_location='right', tooltips=\"$name @A_values: @$name\")\n",
    "\n",
    "\n",
    "        p.vbar_stack(list(tops.keys()),\n",
    "                     x='A_values',\n",
    "                      width=0.9, color=colors, source=source,\n",
    "                     legend=[value(x) for x in list(tops.keys())])\n",
    "\n",
    "    p.y_range.start = 0\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.axis.minor_tick_line_color = None\n",
    "    p.outline_line_color = None\n",
    "    p.legend.location = \"top_right\"\n",
    "    p.legend.orientation = \"horizontal\"\n",
    "\n",
    "\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "    \n",
    "    return(save_plot(p, title,analyse_name, id_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_side_bar(field_list, analyse_name):\n",
    "    sidebar_html = '<nav class=\"w3-sidebar w3-bar-block w3-collapse w3-large w3-theme-l5 w3-animate-left\" id=\"mySidebar\">\\\n",
    "  <a href=\"javascript:void(0)\" onclick=\"w3_close()\" class=\"w3-right w3-xlarge w3-padding-large w3-hover-black w3-hide-large\" title=\"Close Menu\">\\\n",
    "    <i class=\"fa fa-remove\"></i>\\\n",
    "  </a>\\\n",
    "  <h4 class=\"w3-bar-item\"><b>'+ analyse_name + '</b></h4>\\n'\n",
    "    for f in field_list:\n",
    "        sidebar_html = sidebar_html + '<a class=\"w3-bar-item w3-button\" href=\"#' + analyse_name +'-' + f +'\">' + f + ' Distributions</a>\\n'\n",
    "        \n",
    "    sidebar_html = sidebar_html + '</nav>\\\n",
    "    <!-- Overlay effect when opening sidebar on small screens -->\\\n",
    "<div class=\"w3-overlay w3-hide-large\" onclick=\"w3_close()\" style=\"cursor:pointer\" title=\"close side menu\" id=\"myOverlay\"></div>'\n",
    "    return(sidebar_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in sample annotation files \n",
    "## and check compulsory fields and field values\n",
    "## INPUT: path-to-file\n",
    "## OUTPUT: table t\n",
    "def read_sample_annot(file, deli):#, field_std_names, field_std_values):\n",
    "    t = hl.import_table(file, impute=True, delimiter=deli)\n",
    "    # get table fields\n",
    "    col_dict = get_table_fields(t)\n",
    "    # check mandatory fields\n",
    "    if 'Sample' not in list(col_dict.keys()):\n",
    "        sys.exit('Sample does not exist!')\n",
    "    t= t.key_by('Sample')\n",
    "    \n",
    "    if 'isCase' in list(col_dict.keys()):\n",
    "        if col_dict['isCase'] != 'bool':\n",
    "            sys.exit('isCase is not bool')\n",
    "    else:\n",
    "        sys.exit('isCase does not exist!')\n",
    "    \n",
    "    t = t.annotate(CaseControl = hl.cond(t.isCase, 'Case', 'Control'))\n",
    "        \n",
    "    # check other optional fields\n",
    "    if 'isFemale' in list(col_dict.keys()):\n",
    "        if col_dict['isFemale'] != 'bool':\n",
    "            sys.exit('isFemale is not bool!')\n",
    "    else:\n",
    "        sys.exit('isFemale does not exist!')\n",
    "    t = t.annotate(Gender = hl.cond(t.isFemale,'Female', 'Male'))\n",
    "    \n",
    "    return(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(metadata, merge_type, file_type):\n",
    "    mts = []    \n",
    "    ## read in files\n",
    "    if file_type == 'plink':\n",
    "        for file in metadata:\n",
    "            print('plink file: ' + file)\n",
    "            mt_name = file + '.mt'\n",
    "            hl.import_plink(bed= file + '.bed', bim = file + '.bim', fam = file + '.fam',skip_invalid_loci=True, min_partitions=int(numPartitions)).write(mt_name,overwrite=True)\n",
    "            mts.append(hl.read_matrix_table(mt_name))\n",
    "    elif file_type == 'vcf':\n",
    "        for file in metadata:\n",
    "            print('vcf file: ' + file)\n",
    "            mt_name = re.sub(r'vcf(\\.bgz)$','mt', file )\n",
    "            hl.import_vcf(path=file,skip_invalid_loci=True, min_partitions=int(numPartitions)).write(mt_name,overwrite=True)\n",
    "            mts.append(hl.read_matrix_table(mt_name))\n",
    "    else:\n",
    "        sys.exit('Metadata file type not provided or supported!')\n",
    "    \n",
    "    ## merge files\n",
    "    if merge_type == 'variant':\n",
    "        mt = hl.MatrixTable.union_rows(*mts)\n",
    "    elif merge_type == 'sample':\n",
    "        mt = mts[0]\n",
    "        for cur_mt in mts[1:]:\n",
    "            mt = mt.union_cols(cur_mt)\n",
    "    \n",
    "    return(mt, mts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine sample annotation table to the matrix table\n",
    "## INPUT: t(table) ,mt(MatrixTable)\n",
    "## OUTPUT: matrixtable with t joined to the cols\n",
    "def join_rows_cols(t, mt):\n",
    "    # get id info of two tables\n",
    "    id_list_annot = [ re.sub('^(.*=)\\'(.*)\\'(.*)$','\\\\2', str(w) ) for w in t.select().collect()]\n",
    "    id_list_mt = [ re.sub('^(.*=)\\'(.*)\\'(.*)$','\\\\2', str(w) ) for w in mt.cols().key_by('s').select().collect()]\n",
    "   \n",
    "    # compare id info\n",
    "    isSubset = all(elem in id_list_annot  for elem in id_list_mt)\n",
    "    if not isSubset:\n",
    "        sys.exit('Sample annotations missing!')\n",
    "    # join mt\n",
    "    mt = mt.annotate_cols(pheno = t[mt.s])\n",
    "    # break multiallelic\n",
    "    mt = hl.split_multi_hts(mt)\n",
    "    ## get variant_qc and sample_qc\n",
    "    mt = hl.variant_qc(mt)\n",
    "    mt = hl.sample_qc(mt)\n",
    "    # remove duplicates\n",
    "    mt = mt.distinct_by_row()\n",
    "    mt = mt.distinct_by_col()\n",
    "    return(mt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_init_summary_html(sample_annot, metadata, mt, mts):#, field_std_names, field_std_values):\n",
    "    \n",
    "    summary_html = '<p> ' + '<b>Annotation File: </b>' \n",
    "    summary_html = summary_html + '<ul style=\"list-style-type: disc;\">\\n'\n",
    "    ## for each annotation file\n",
    "    for file in sample_annot:\n",
    "        summary_html = summary_html + '<li>' + file + '</li>\\n'\n",
    "    summary_html = summary_html + '</ul>\\n' + '<b>VCF file: </b>' + '<ul style=\"list-style-type: disc;\">\\n'    \n",
    "    for file in metadata:\n",
    "        summary_html = summary_html + '<li>' + file + '</li>\\n'\n",
    "    summary_html = summary_html + '</ul>\\n' \n",
    "    \n",
    "    for i in range(0,len(metadata)):\n",
    "        summary_html = summary_html + '<b>metadata filename: </b>' + metadata[i] + '<br>\\n'\n",
    "        summary_html = summary_html + '<b># samples: </b>' + str(mts[i].count_cols()) + '<br>\\n'\n",
    "        summary_html = summary_html + '<b># variants: </b>' + str(mts[i].count_rows()) + '<br>\\n'\n",
    "        summary_html = summary_html + '<b>Call rate: </b>' + str(mt.count_rows()/mts[i].count_rows()) + '<br>'\n",
    "    summary_html = summary_html + '<b><i>After joining sample annotations and vcf files....</i></b><br>'\n",
    "    summary_html = summary_html + '<b>Total # of Sample analysed: </b>' + str(mt.count_cols()) + '<br>'\n",
    "    summary_html = summary_html + '<b>Total # of Variant analysed: </b>' + str(mt.count_rows()) + '<br>'\n",
    "    \n",
    "    summary_html = summary_html + '</p>'\n",
    "    \n",
    "    ## save file\n",
    "    # write into html file\n",
    "    filepath = \"htmls/summary.html\"\n",
    "    directory = os.path.dirname(filepath)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    f = open(filepath, \"w+\")\n",
    "    f.write(summary_html)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_saved_summary_html(mt,mt_name):\n",
    "    # read saved mt\n",
    "    \n",
    "    summary_html = '<p> '\n",
    "    summary_html = summary_html + '<b>MatrixTable File: </b>' + mt_name + '<br>'\n",
    "    summary_html = summary_html + '<b># of Sample analysed: </b>' + str(mt.count_cols()) + '<br>'\n",
    "    summary_html = summary_html + '<b># of Variants analysed: </b>'+ str(mt.count_rows()) + '<br>'\n",
    "   \n",
    "    summary_html = summary_html + '</p>'\n",
    "    \n",
    "    ## save file\n",
    "    # write into html file\n",
    "    filepath = \"htmls/summary.html\"\n",
    "    directory = os.path.dirname(filepath)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    f = open(filepath, \"w+\")\n",
    "    f.write(summary_html)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if sample_annot_file_list and mt_file_list :\n",
    "    # read in files\n",
    "    t = read_sample_annot(sample_annot_file_list, sample_annot_deli)\n",
    "    mt, mts = read_metadata(mt_file_list, mt_merge_type, mt_file_type)\n",
    "    mt = join_rows_cols(t, mt)\n",
    "    # create result directory and change directory\n",
    "    shutil.copytree('templates', result_dir)\n",
    "    os.chdir(result_dir)\n",
    "    # print out summary result\n",
    "    print_init_summary_html(sample_annot_file_list, mt_file_list, mt, mts)\n",
    "elif mt_name in globals():\n",
    "    # read saved mt\n",
    "    mt = hl.read_matrix_table(mt_name)\n",
    "    # create result directory and change directory\n",
    "    shutil.copytree('templates', result_dir)\n",
    "    os.chdir(result_dir)\n",
    "    # print out summary result\n",
    "    print_saved_summary_html(mt, mt_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input file infos and read files (2 options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read from sample annotation files and vcf files\n",
    "#### sample annotations:\n",
    "tab-delimited\n",
    "header needed\n",
    "compulsory fields: SampleID and isCase (bool)\n",
    "optional fields (analyse if exist): isFemale/isMale, Population, SuperPopulation\n",
    "field names must be the same as above in the header\n",
    "#### vcf:\n",
    "-standard vcf format (can be bgz or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Annotation Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_annot_info(mt, downsample_percent, graph_type, preset_fields):\n",
    "    analyse_name = 'Sample Annotations'\n",
    "    plot_html = {}\n",
    "    for f in preset_fields:\n",
    "        plot_html[f] = '<div>\\\n",
    "        <h2 id=\"' + f +'\" class=\"w3-text-teal\">' + f + '</h2>\\n'\n",
    "    isVariant = False\n",
    "    col_dict = get_table_fields(mt.cols().select('pheno').key_by('pheno').select().flatten())\n",
    "    \n",
    "    cat_fields = {}\n",
    "    fns = {}    \n",
    "    for k in list(col_dict.keys()):\n",
    "        field_names = k.split('.')\n",
    "        print(field_names)\n",
    "        if len(field_names) == 2:\n",
    "            field = mt[field_names[0]][field_names[1]]\n",
    "            field_name = field_names[1]\n",
    "            fns[k] = field_name\n",
    "        else:\n",
    "            print('error too many field depth')\n",
    "            break\n",
    "        if field_name not in preset_fields:\n",
    "            print('Found non-preset fields: ' + field_name)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        cat_fields[k] = isCat(mt, field, isVariant)\n",
    "        if re.match(r'.*int.*',col_dict[k], re.M) or re.match(r'.*float.*',col_dict[k],re.M) and not isCat(mt, field, isVariant):\n",
    "            # numbers -> histgram\n",
    "            plot_html[field_name] = plot_html[field_name] + get_hist_graph(mt,field,field_name,downsample_percent,isVariant, analyse_name)\n",
    "        else:\n",
    "            # catogorical values and non-float types get bar_graphs\n",
    "            plot_html[field_name] = plot_html[field_name]  + get_bar_graph(mt, field, field_name, isVariant, analyse_name)\n",
    "    \n",
    "    #get combined graphs\n",
    "    for f in cat_fields.keys():\n",
    "        for f2 in cat_fields.keys():\n",
    "            if cat_fields[f2] == True and f != f2:\n",
    "                print('f:' + f + ' f2: ' + f2)\n",
    "                plot_html[fns[f]] = plot_html[fns[f]] + get_bar_graph_A_by_B(mt,[f,f2],graph_type, analyse_name)\n",
    "    plot_html_all = ''\n",
    "    plot_html_all = create_side_bar(preset_fields, analyse_name)\n",
    "    plot_html_all = plot_html_all + '<!-- Main content: shift it to the right by 250 pixels when the sidebar is visible -->\\\n",
    "<div class=\"w3-main\" style=\"margin-left:250px\">\\\n",
    "  <div class=\"w3-row w3-padding-64\">\\\n",
    "    <div class=\"w3-container\">\\\n",
    "      <h1 id=\"sa\" class=\"w3-text-teal\">Analysis of Sample annotations data</h1>\\\n",
    "      <p>some description if you want</p>\\n'\n",
    "\n",
    "    for s in preset_fields:\n",
    "        plot_html_all = plot_html_all + plot_html[s] + '</div>'\n",
    "    plot_html_all = plot_html_all + '</div>\\n</div>\\n</div>\\n'\n",
    "    return(plot_html_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'isCase' in fields_to_plot:\n",
    "    fields_to_plot.remove('isCase')\n",
    "    fields_to_plot.append('CaseControl')\n",
    "if 'isFemale' in fields_to_plot:\n",
    "    fields_to_plot.remove('isFemale')\n",
    "    fields_to_plot.append('Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_html = get_sample_annot_info(mt,downsample_percent,graph_type, fields_to_plot)\n",
    "    \n",
    "# write into html file\n",
    "filepath = \"htmls/sample_annot.html\"\n",
    "f = open(filepath, \"w+\")\n",
    "f.write(plot_html)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given a matrixTable\n",
    "## plot all plots for each field in sample_qc and variant_qc\n",
    "## INPUT: matrixTable, isVaraiant(boolean), downsample_percent, analyse_name\n",
    "## OUTPUT: list of plots\n",
    "def get_qc_info(mt, isVariant, downsample_percent, analyse_name):\n",
    "\n",
    "    plot_html = '<!-- Main content: shift it to the right by 250 pixels when the sidebar is visible -->\\\n",
    "<div class=\"w3-main\" style=\"margin-left:250px\">\\\n",
    "  <div class=\"w3-row w3-padding-64\">\\\n",
    "    <div class=\"w3-container\">\\\n",
    "      <h1 id=\"sa\" class=\"w3-text-teal\">Per '+ analyse_name +' analysis</h1>\\\n",
    "      <p>some description if you want</p>\\n'\n",
    "    if isVariant:\n",
    "        col_dict = get_table_fields(mt.rows().select('variant_qc').key_by('variant_qc').select().flatten())\n",
    "    else:\n",
    "        col_dict = get_table_fields(mt.cols().select('sample_qc').key_by('sample_qc').select().flatten())\n",
    "    \n",
    "    sidebar_field_list = []\n",
    "    for k in list(col_dict.keys()):\n",
    "        field_names = k.split('.')\n",
    "        if len(field_names) == 2:\n",
    "            field = mt[field_names[0]][field_names[1]]\n",
    "            field_name = field_names[1]\n",
    "        elif len(field_names) == 3:\n",
    "            continue\n",
    "            field = mt[field_names[0]][field_names[1]][field_names[2]]\n",
    "            field_name = field_names[2]\n",
    "        else:\n",
    "            print('error too many field depth')\n",
    "            break\n",
    "\n",
    "        if re.match(r'.*int.*',col_dict[k], re.M) or re.match(r'.*float.*',col_dict[k],re.M):\n",
    "            # numbers -> histgram\n",
    "            if re.match(r'^array',col_dict[k],re.M):\n",
    "                for i in range(0,2):\n",
    "                    if i == 0:\n",
    "                        field_name_x = field_name + '_ref_allele' \n",
    "                    else:\n",
    "                        field_name_x = field_name + '_alt_allele'\n",
    "                    sidebar_field_list.append(field_name_x)\n",
    "                    plot_html = plot_html + get_hist_graph(mt, field[i],field_name_x,downsample_percent,isVariant, analyse_name)\n",
    "            else:\n",
    "                print(field_name)\n",
    "                sidebar_field_list.append(field_name)\n",
    "                plot_html = plot_html + get_hist_graph(mt, field,field_name,downsample_percent,isVariant, analyse_name)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    sidebar_html = create_side_bar(sidebar_field_list, analyse_name)\n",
    "    plot_html = sidebar_html + plot_html + '</div>\\n</div>\\n'\n",
    "    \n",
    "    return(plot_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct variant QC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_html = get_qc_info(mt, True, downsample_percent, 'Variant QC')\n",
    "    \n",
    "# write into html file\n",
    "filepath = \"htmls/variant_qc.html\"\n",
    "f = open(filepath, \"w+\")\n",
    "f.write(plot_html)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct sample QC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_html = get_qc_info(mt, False, downsample_percent, 'Sample QC')\n",
    "plot_html = get_qc_info(mt, False, 1, 'Sample QC')\n",
    "\n",
    "# write into html file\n",
    "filepath = \"htmls/sample_qc.html\"\n",
    "f = open(filepath, \"w+\")\n",
    "f.write(plot_html)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCA_scatter(x,y,label,title=None, xlabel=None, ylabel=None, collect_all=False, n_divisions=500, size=4):\n",
    "\n",
    "    palette = d3['Category10'][10]\n",
    "    \n",
    "    # enlist data from expression\n",
    "    if collect_all:\n",
    "        res = hl.tuple([x, y, label]).collect()\n",
    "        label = [point[2] for point in res]\n",
    "    else:\n",
    "        agg_f = x._aggregation_method()\n",
    "        res = agg_f(hl.agg.downsample(x, y, label=label, n_divisions=n_divisions))\n",
    "        label = [point[2][0] for point in res]\n",
    "\n",
    "    x = [point[0] for point in res]\n",
    "    y = [point[1] for point in res]\n",
    "    \n",
    "    p = figure(title=title, x_axis_label=xlabel, y_axis_label=ylabel, tooltips = '@label', background_fill_color='#EEEEEE')\n",
    "    factors = list(set(label))\n",
    "    fields = dict(x=x, y=y, label=label)\n",
    "    source = ColumnDataSource(fields)\n",
    "    if len(factors) > len(palette):\n",
    "        color_gen = cycle(palette)\n",
    "        colors = []\n",
    "        for i in range(0, len(factors)):\n",
    "            colors.append(next(color_gen))\n",
    "    else:\n",
    "        colors = palette[0:len(factors)]\n",
    "\n",
    "    color_mapper = CategoricalColorMapper(factors=factors, palette=colors)\n",
    "    p.circle('x', 'y', alpha=0.5, source=source,size=size, color={'field': 'label', 'transform': color_mapper}, legend='label')\n",
    "    #show(p)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Principle Component Analysis\n",
    "## INPUT: mt(matrixTable), number of factors(int)\n",
    "## OUTPUT: annotated mt, plot_html\n",
    "def get_PCA_graph(mt, n_factor, field_list):\n",
    "    analyse_name = 'PCA'\n",
    "    plot_html = create_side_bar(['CaseControl'] + field_list, analyse_name)\n",
    "    plot_html = plot_html + '<div class=\"w3-main\" style=\"margin-left:250px\">\\\n",
    "  <div class=\"w3-row w3-padding-64\">\\\n",
    "    <div class=\"w3-container\">\\\n",
    "      <h1 id=\"vqc\" class=\"w3-text-teal\">PCA Analysis</h1>\\\n",
    "      <p>PCA analysis of factor '+ str(n_factor) + ' </p>'\n",
    "    eigenvalues, pcs, loadings = hl.hwe_normalized_pca(mt.GT, k=n_factor)\n",
    "    print('Done PCA analysis')\n",
    "    \n",
    "    ## plot pcs per sample\n",
    "    mt = mt.annotate_cols(pcs = pcs[mt.s].scores)\n",
    "    ## plot all pcs for case/control\n",
    "    for i in range(0,n_factor):\n",
    "        j = i+1\n",
    "        while j < n_factor:\n",
    "            print('Starting plotting PC'+ str(i) + ' vs PC' + str(j))\n",
    "            x = 'PC' + str(i+1)\n",
    "            y = 'PC' + str(j+1)\n",
    "            title =  y + ' vs ' +  x \n",
    "            title = 'CaseControl PCA - ' + y + ' vs ' +  x \n",
    "            if i == 0 and j == 1:\n",
    "                id_link = analyse_name + '-' + 'CaseControl'\n",
    "            else:\n",
    "                id_link = 'pca-cc-'+str(i)+str(j)\n",
    "            \n",
    "            p = get_PCA_scatter(mt.pcs[i],\n",
    "                            mt.pcs[j],\n",
    "                            label=mt.pheno.CaseControl,\n",
    "                            title=title, xlabel=x, ylabel=y)\n",
    "            plot_html = plot_html + save_plot(p,title,analyse_name,id_link)\n",
    "            j = j + 1\n",
    "            \n",
    "    ## plot 1&2 for others \n",
    "    col_dict = get_table_fields(mt.cols().select('pheno').key_by('pheno').select().flatten())\n",
    "    for f in list(col_dict.keys()):\n",
    "        field_names = f.split('.')\n",
    "        if len(field_names) == 2:\n",
    "            field_name = field_names[1]\n",
    "        if field_name in field_list:\n",
    "            title = field_name + ' PCA - PC2 vs PC1'\n",
    "            id_link = analyse_name + '-' + field_name\n",
    "            p = get_PCA_scatter(mt.pcs[0],\n",
    "                            mt.pcs[1],\n",
    "                            label=mt[field_names[0]][field_names[1]],\n",
    "                            title=title, xlabel='PC1', ylabel='PC2')\n",
    "            plot_html = plot_html + save_plot(p,title,analyse_name,id_link)\n",
    "    plot_html = plot_html + '</div>\\n</div>'        \n",
    "    \n",
    "    return(mt, plot_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CaseControl' in fields_to_plot:\n",
    "    fields_to_plot.remove('CaseControl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mt, plot_html = get_PCA_graph(mt, n_factor, fields_to_plot)\n",
    "# write into html file\n",
    "filepath = \"htmls/pca.html\"\n",
    "f = open(filepath, \"w+\")\n",
    "f.write(plot_html)\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Manhattan Plot (must after PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manhattan_graph(mt,method, n_divisions=500):\n",
    "    title = 'Manhattan plot (' + method +')'\n",
    "    id_link = 'Logistic Regression-'+method\n",
    "    field_name = 'logreg_' + method\n",
    "    # plotting\n",
    "    hover_fields = {'rsid': mt.rsid,\n",
    "                'locus': mt.locus,\n",
    "                'p_value': mt[field_name]['p_value']}\n",
    "    p = hl.plot.manhattan(pvals=mt[field_name]['p_value'], hover_fields=hover_fields, title=title, n_divisions=n_divisions)\n",
    "\n",
    "    return(save_plot(p, title,'Logistic Regression', id_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qq_graph(mt,method, n_divisions=500 ):\n",
    "    title = 'Q-Q plot (' + method +')'\n",
    "    id_link = 'lgqq-'+method\n",
    "    field_name = 'logreg_' + method\n",
    "    # plotting\n",
    "    p = hl.plot.qq(pvals=mt[field_name]['p_value'], n_divisions = n_divisions)\n",
    "    return(save_plot(p, title,'Logistic Regression', id_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression (mt, method, n_factor):\n",
    "    # logistic regression\n",
    "    covariates = [mt.pcs[i] for i in range(0,n_factor)]\n",
    "    if 'pheno.isFemale' in list(get_table_fields(mt.cols().select('pheno').flatten()).keys()):\n",
    "        covariates.append(mt.pheno.isFemale)\n",
    "\n",
    "    result = hl.logistic_regression_rows(test =method, \n",
    "                                          y=mt.pheno.isCase,\n",
    "                                          x=mt.GT.n_alt_alleles(),\n",
    "                                          covariates=covariates)\n",
    "    # annotate matrixtable\n",
    "    field_name = 'logreg_' + method\n",
    "    mt = mt.annotate_rows( logreg = result[mt.locus, mt.alleles])\n",
    "    if field_name in mt._fields:\n",
    "        mt = mt.drop(mt[field_name])\n",
    "    mt = mt.rename({'logreg': field_name})\n",
    "    \n",
    "    return(mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wald\n",
    "mt = logistic_regression(mt, 'wald', n_factor)\n",
    "mt.count()\n",
    "plot_html_wald = get_manhattan_graph(mt, 'wald', 150)\n",
    "plot_html_wald = plot_html_wald + get_qq_graph(mt, 'wald', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score\n",
    "mt = logistic_regression(mt, 'score', n_factor)\n",
    "mt.count()\n",
    "plot_html_score = get_manhattan_graph(mt, 'score', 450)\n",
    "plot_html_score = plot_html_score + get_qq_graph(mt, 'score', 450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lrt\n",
    "mt = logistic_regression(mt, 'lrt', n_factor)\n",
    "mt.count()\n",
    "plot_html_lrt = get_manhattan_graph(mt, 'lrt', 150)\n",
    "plot_html_lrt = plot_html_lrt + get_qq_graph(mt, 'lrt', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_html = create_side_bar(['wald','score','lrt'],'Logistic Regression')\n",
    "plot_html = plot_html + '<div class=\"w3-main\" style=\"margin-left:250px\">\\\n",
    "    <div class=\"w3-row w3-padding-64\">\\\n",
    "    <div class=\"w3-container\">\\\n",
    "      <h1 id=\"vqc\" class=\"w3-text-teal\">Logistic Regression</h1>\\\n",
    "      <p>Manhattan Plots of p-values from Logistic Regressions(3 methods)</p>\\n'\n",
    "plot_html = plot_html + plot_html_wald + plot_html_score + plot_html_lrt + '</div>\\n</div>\\n'\n",
    "# write into html file\n",
    "filepath = \"htmls/manhattan.html\"\n",
    "f = open(filepath, \"w+\")\n",
    "f.write(plot_html)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant-Spark Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export current LR-ed matrix and conduct variant-spark analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vs_analysis(mt,filepath):\n",
    "    ## generate annotation files\n",
    "    t = mt.cols()\n",
    "    t = t.annotate(vs_label = hl.cond(t.pheno.isCase,1,0))\n",
    "    annot_file_tsv = filepath + '_annotations.tsv'\n",
    "    t.select('vs_label').export(annot_file_tsv)\n",
    "    annot_file_csv = filepath + '_annotations.csv'\n",
    "    make_annot_csv_cmd = \"tr '\\t' ',' < \" + annot_file_tsv +\" > \" + annot_file_csv\n",
    "    subprocess.call(make_annot_csv_cmd, shell=True)\n",
    "\n",
    "    \n",
    "    ## prepare vcf file\n",
    "    bgz_file = filepath + '.vcf.bgz'\n",
    "    hl.export_vcf(mt, bgz_file)\n",
    "    bz2_file = filepath +'.vcf.bz2'\n",
    "    convert_bgz_cmd = 'zcat -dc ' + bgz_file + ' | pbzip2 -p' + str(numCPU) + ' > ' + bz2_file\n",
    "    subprocess.call(convert_bgz_cmd, shell=True)\n",
    "    \n",
    "    ## conduct vs_analysis\n",
    "    vs_out_file = filepath + '_vs.out'\n",
    "    vs_command = PATH_TO_VS +' importance -ff ' + annot_file_csv + ' -fc vs_label -if ' + bz2_file + ' -of ' + vs_out_file + ' -on 100000000 -rbs 100 -rmtf ' + str(mtry_fraction) + ' -rn ' + str(num_of_tree) + ' -ro -sp ' + str(numPartitions)\n",
    "    subprocess.call(vs_command, shell=True)\n",
    "    \n",
    "    ## editing output file\n",
    "    vs_hail_tsv_file = filepath + '_vs_hail.tsv'\n",
    "    edit_cmd = 'tail -n +2 ' + vs_out_file + \" | tr _ '\\t' | tr , '\\t' | awk \" + '\\'{print($1\":\"$2\"\\t[\\\\\"\"$3\"\\\\\",\\\\\"\"$4\"\\\\\"]\\t\"$5)}\\'' + ' > ' + vs_hail_tsv_file\n",
    "    subprocess.call(edit_cmd, shell=True)\n",
    "    add_header_cmd = \"sed -i '1i \\locus\\talleles\\tvs_score' \" + vs_hail_tsv_file\n",
    "    subprocess.call(add_header_cmd, shell=True)\n",
    "    return(vs_hail_tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in vs result file and add it to the matrixtable\n",
    "def read_vs_table(file, mt):\n",
    "    t = hl.import_table(file, types={'locus': hl.tlocus('GRCh37'), 'alleles': hl.tarray(hl.tstr), 'vs_score': hl.tfloat})\n",
    "    t = t.key_by('locus','alleles')\n",
    "    mt = mt.annotate_rows(vs_score = t[mt.locus, mt.alleles].vs_score)\n",
    "    return(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vs_manhattan(mt):\n",
    "    mt = mt.annotate_rows(vs_stats = mt.aggregate_rows(hl.agg.stats(mt['vs_score'])))\n",
    "    mt = mt.annotate_rows(z_score = (mt['vs_score'] - mt.vs_stats.mean)/mt.vs_stats.stdev)\n",
    "    mt = mt.annotate_rows(vs_score_converted = 10** -mt.z_score)\n",
    "    title = 'Variant-Spark Manhattan plot'\n",
    "    id_link = 'man-vs'\n",
    "    folder = 'Variant Spark'\n",
    "    hover_fields = {'rsid': mt.rsid, 'vs_score': mt.vs_score}\n",
    "    p = hl.plot.manhattan(pvals=mt.vs_score_converted, hover_fields=hover_fields, title=title)\n",
    "    p.yaxis.axis_label = 'Z score of importantce score by VS'\n",
    "    return(save_plot(p, title, folder, id_link))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = re.sub(r'\\s', '_', analysis_name)\n",
    "filepath = result_dir + '/output/variant-spark/' + filename\n",
    "directory = os.path.dirname(filepath)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "vs_result = vs_analysis(mt, filepath)\n",
    "mt = read_vs_table(vs_result,mt)\n",
    "plot_html = get_vs_manhattan(mt)\n",
    "\n",
    "# write into html file\n",
    "filepath = \"htmls/variant-spark.html\"\n",
    "f = open(filepath, \"w+\")\n",
    "f.write(plot_html)\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export as a matrix table - ready to use for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'annotated_' + re.sub(r'\\s', '_', analysis_name)\n",
    "output_prefix = result_dir + '/output/' + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_name = output_prefix + '.mt'\n",
    "mt.write(mt_name,overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export as vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = output_prefix + '.vcf.bgz' # extension needed\n",
    "hl.export_vcf(mt, output_path) # 1 output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export as plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = output_prefix # no extension needed\n",
    "hl.export_plink(mt, output_path) # 3 output files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove files\n",
    "shutil.rmtree(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
