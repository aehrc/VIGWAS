{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# ViGWAS\n### This notebook is written using Hail v0.2 and VariantSpark."}, {"metadata": {}, "cell_type": "markdown", "source": "# User Block"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## read from sample annotations and vcf files\nsample_annot_deli = ',' #'\\t' for tsv and ',' for csv\n\n#S3_Path='s3://YOUR_BUCKET_OR_PATH/ViGWAS/'\nS3_Path='s3://csiro-tb/notebooks/Hail2/ViGWAS/'\n\n# Cccept multiple sample annotation file\nsample_annot_file_list = [S3_Path+'sample_input/hipster.csv']\n\n# support 'vcf' or 'plink'\nmt_file_type = 'vcf'\n\n# 'variant' for different variants in different files, 'sample' for same variants in different files\nmt_merge_type = 'sample' \n\nif (mt_merge_type=='sample'):\n    mt_file_list = [S3_Path+'sample_input/S1.vcf.bgz', S3_Path+'sample_input/S2.vcf.bgz']\n    # The name of result directory in your S3_Path\n    analysis_name = 'my_analysis_s'\nelse:\n    mt_file_list = [S3_Path+'sample_input/V1.vcf.bgz', S3_Path+'sample_input/V2.vcf.bgz']\n    # The name of result directory in your S3_Path\n    analysis_name = 'my_analysis_v'\n    \n## For plink files (bed bim fam), provide prefix only\n#mt_file_list = ['paths/to/plink-1', 'paths/to/plink-2']\n\n\n\ndownsample_percent = 0.01 # ratio of variants to be selected (randomly) for QC plots\ngraph_type = 'stack' # or 'group': representation when 2 variables are plotted at the same time\nfields_to_plot = ['isFemale', 'Population', 'isCase'] # list of fields in sample annotations for QC plotting\n\nn_factor = 4 # number of factors for PCA\n\n## variant-spark\nmtry_fraction=0.1\nnum_of_tree=100\nbatch_size=25\nmin_node_size=50\nmax_depth=10\n\n## Some configs\nnumCPU = 256\nmemory = '60g'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Environment initialization"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## Environment init\n\nimport os\nfrom pyspark import SparkContext\nsc = SparkContext()\n\nimport hail as hl\nimport varspark.hail as vshl\nvshl.init(sc=sc)\n\nfrom bokeh.io import output_notebook, show\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, FactorRange, LabelSet, Label\nfrom bokeh.transform import factor_cmap\nfrom bokeh.palettes import d3\nfrom bokeh.core.properties import value\nfrom bokeh.embed import file_html\nfrom bokeh.resources import CDN\nfrom bokeh.layouts import gridplot\nfrom bokeh.models.mappers import CategoricalColorMapper\n\nfrom pprint import pprint\n#output_notebook()\n\nimport re\nimport numpy as np\nimport math as math\nimport sys\nimport operator\nfrom collections import OrderedDict\nimport subprocess\nfrom itertools import cycle\nimport shutil", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "%%sh\nsudo yum install -y git\ncd ~\nrm -rf VIGWAS\ngit clone https://github.com/aehrc/VIGWAS.git\necho \"==========\"\nls -l", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "os.chdir('/home/hadoop/VIGWAS/')\nresult_dir = re.sub(r'\\s','_',analysis_name)\ncwd = os.getcwd()\nresult_dir = cwd + '/' +result_dir\nprint(result_dir)\nnumPartitions = numCPU*4", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Some general functions"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## loop around fileds and generate graph for each field\n#  get rows field count, names, types\n## INPUT: table \n## OUTPUT: col_count(int), col_names(list<str>), col_types(list<str>)\ndef get_table_fields(t):\n    col_names = list(t.row.dtype.keys())\n    col_types = list(t.row.dtype.values())\n    col_types = [str(w).replace('dtype', '') for w in col_types]\n    col_dict = dict(zip(col_names,col_types))\n    return(col_dict)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## save plot in a html file\n## and write a plot division with proper headings in html\n## INPUT: bokeh figure object p, filename_to_save(str), folder_to_save(str), id for the division in html(str)\n## OUTPUT: division html(str)\ndef save_plot(p, title, folder, id_link):\n    html = file_html(p, CDN, title)\n    filepath = 'plots/'+folder+'/'+title+'.html'\n    directory = os.path.dirname(filepath)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    f = open(filepath, \"w+\")\n    f.write(html)\n    f.close()\n    plot_html = \"<div>\\n<h3 id='\" + id_link + \"' class='w3-text-teal'>\" + title + \"</h3>\\n\"\n    plot_html = plot_html + '<object width=\"100%\" height=\"' + str(p.plot_height+100) + '\" data=\"../'+filepath+'\"></object>\\n'\n    plot_html = plot_html + \"</div>\\n<br><br>\\n\"\n    return(plot_html)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## given a float/int field in rows/cols table\n## generate a histogram of the field with specified downsample percent\n## INPUT: matrixtable, field(expression), field_name(str), downsample_percent(float), analyse_name\n## OUTPUT: bokeh plot\ndef get_hist_graph(mt, field, field_name, downsample_percent, isVariant, analyse_name):\n    title=field_name + ' Histogram'\n    id_link = analyse_name + '-' + field_name\n    \n    if isVariant:\n        stats = mt.aggregate_rows(hl.expr.aggregators.stats(field))\n        if stats == None:\n            plot_html = \"<div>\\n<h3 id='\" + id_link + \"' class='w3-text-teal'>\" + title + \"</h3>\\n\"\n            plot_html = plot_html + '<p> divisor equals 0 exist. Unable to generate a histogram with NA values </p><br>'\n            plot_html = plot_html + \"</div>\\n<br><br>\\n\"\n            return(plot_html)\n        unique_count = len(mt.aggregate_rows(hl.expr.aggregators.counter(field)))\n        hist = mt.aggregate_rows(hl.expr.aggregators.hist(field,stats.min-1,stats.max+1,int(unique_count*downsample_percent)+1))\n    else:\n        stats = mt.aggregate_cols(hl.expr.aggregators.stats(field))\n        if stats == None:\n            plot_html = \"<div>\\n<h3 id='\" + id_link + \"' class='w3-text-teal'>\" + title + \"</h3>\\n\"\n            plot_html = plot_html + '<p> divisor equals 0 exist. Unable to generate a histogram with NA values </p><br>'\n            plot_html = plot_html + \"</div>\\n<br><br>\\n\"\n            return(plot_html)\n        unique_count = len(mt.aggregate_cols(hl.expr.aggregators.counter(field)))\n        hist = mt.aggregate_cols(hl.expr.aggregators.hist(field,stats.min-1,stats.max+1,int(unique_count*downsample_percent)+1))\n    \n    p = hl.plot.histogram(hist, legend=field_name, title=title)\n    print(title)\n    return(save_plot(p, title,analyse_name, id_link))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "### get unique value counts of given field\ndef get_unique_values(mt, field, isVariant):\n    if isVariant:\n        unique_values = mt.aggregate_rows(hl.expr.aggregators.counter(field))\n    else:    \n        unique_values = mt.aggregate_cols(hl.expr.aggregators.counter(field))\n\n    return unique_values\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## given a matrixtable and a row/col field\n## find if the field is categorical or not\ndef isCat(mt, field, isVariant):\n    unique_count = len(get_unique_values(mt, field, isVariant))\n    if unique_count <= 10:\n        isCat = True\n    else:\n        isCat = False\n    \n    return isCat", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## given a matrix table and a field\n## produce a bar graph of the field\n## INPUT: matrixtable, field<expression>, field_name<str>, isVariant<boolean>, analyse_name<str>\n## OUTPUT: bargraph p\ndef get_bar_graph(mt, field, field_name, isVariant, analyse_name):\n    legend = field_name\n    title = legend + ' bar graph'\n    width = 0.5\n    \n    unique_values = get_unique_values(mt,field, isVariant)\n    top_list = list(unique_values.values())\n    x_co_names = [ str(i) for i in list(unique_values.keys())]\n    \n    source = ColumnDataSource(data=dict(x_names = x_co_names, tops = top_list))\n    p = figure(title=title, x_range = x_co_names, x_axis_label=legend, y_axis_label='Frequency', background_fill_color='#EEEEEE',\n              tooltips=\"@x_names: @tops\", plot_height =600)\n    p.vbar(\n        x = 'x_names', width=width, top='tops', bottom=0, source=source)\n    id_link = analyse_name + '-' +field_name\n    #show(p)\n    return(save_plot(p, title,analyse_name,id_link))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## for get_bar_graph_A_by_B\n## get top values for combo keys\n## add 0 to non-exist entries\n## INPUT: A_values(list), filtered matrix table, selected filtered fieldA(expr), cols/rows(boolean)\ndef get_top_values(A_values,mt_filtered, field_filtered, isVariant):\n    tops = get_unique_values(mt_filtered, field_filtered, isVariant)\n    for a in A_values:\n        if a not in tops.keys():\n            tops[a] = 0\n    return [tops[a] for a in A_values]", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## for get_bar_graph_A_by_B\n## map data from multi series into one tuple orderly\n## for grouped bar graph input\n## INPUT:  counts of each combo keyed by A_values(dict)\n## OUTPUT: A tuple of counts ordered by x (combo key variable)\ndef map_counts(tops):\n    counts = []\n    index = 0\n    key_names = list(tops.keys())\n    while index < len(tops[key_names[0]]):\n        list_to_append = [tops[a][index]for a in key_names]\n        counts.extend(list_to_append)\n        index = index + 1\n    counts = tuple(counts)\n    \n    return(counts)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## get A grouped by B\n## INPUT: matrixtable, field_names(list<str>) [A,B](full name after mt), graph_type(str) :group or stack, analyse_name(str)\n## OUTPUT: a bar graph of A by B\ndef get_bar_graph_A_by_B(mt, field_names, graph_type, analyse_name):\n    width = 0.5\n    palette = d3['Category10'][10]\n    # get field names and unique values\n    name_indexes = [ field_name.split('.') for field_name in field_names]\n    field_values = [list(get_unique_values(mt,mt[name[0]][name[1]],False).keys()) for name in name_indexes]\n    title = name_indexes[0][1] + ' by ' + name_indexes[1][1]\n    id_link = analyse_name + '-' + name_indexes[0][1] + 'by' + name_indexes[1][1]\n    # get filter data and feed into top\n    tops = {}\n    for v in field_values[1]:\n        mt_filtered = mt.filter_cols(mt[name_indexes[1][0]][name_indexes[1][1]] == v, keep=True)\n        field_filtered = mt_filtered[name_indexes[0][0]][name_indexes[0][1]]\n        tops[str(v)] = list(get_top_values(field_values[0], mt_filtered, field_filtered, False))\n    # string type everything\n    field_values[0] = [str(x) for x in field_values[0]]\n    field_values[1] = [str(x) for x in field_values[1]]\n    \n    if graph_type == 'group':\n        # format and map data\n        x = [(str(fn1), str(fn2)) for fn1 in field_values[0] for fn2 in field_values[1]]\n        counts = map_counts(tops)\n        labels = [ str(fn2) for fn1 in field_values[0] for fn2 in field_values[1]]\n        source = ColumnDataSource(data=dict(x=x, counts=counts,labels= labels))\n\n        p = figure(x_range = FactorRange(*x), plot_height=600, title=title, tooltips=\"@x: @counts\")\n\n        p.vbar(x='x', top='counts', width=0.9, source=source,\n               fill_color=factor_cmap('x', \n                                      palette=palette, \n                                      factors=[str(value) for value in field_values[1]],\n                                      start=1, end=2),\n                legend='labels')\n    elif graph_type == 'stack':\n        data = {'A_values': field_values[0]}\n        data.update(tops)\n        source = ColumnDataSource(data)\n        colors = palette[0:len(field_values[1])]\n        print(field_values[0])\n        p = figure(x_range=field_values[0], plot_height=600, title=title,\n                  toolbar_location='right', tooltips=\"$name @A_values: @$name\")\n\n\n        p.vbar_stack(list(tops.keys()),\n                     x='A_values',\n                      width=0.9, color=colors, source=source,\n                     legend=[value(x) for x in list(tops.keys())])\n\n    p.y_range.start = 0\n    p.xgrid.grid_line_color = None\n    p.axis.minor_tick_line_color = None\n    p.outline_line_color = None\n    p.legend.location = \"top_right\"\n    p.legend.orientation = \"horizontal\"\n\n\n    p.xaxis.major_label_orientation = 1\n    p.xgrid.grid_line_color = None\n    \n    return(save_plot(p, title,analyse_name, id_link))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def create_side_bar(field_list, analyse_name):\n    sidebar_html = '<nav class=\"w3-sidebar w3-bar-block w3-collapse w3-large w3-theme-l5 w3-animate-left\" id=\"mySidebar\">\\\n  <a href=\"javascript:void(0)\" onclick=\"w3_close()\" class=\"w3-right w3-xlarge w3-padding-large w3-hover-black w3-hide-large\" title=\"Close Menu\">\\\n    <i class=\"fa fa-remove\"></i>\\\n  </a>\\\n  <h4 class=\"w3-bar-item\"><b>'+ analyse_name + '</b></h4>\\n'\n    for f in field_list:\n        sidebar_html = sidebar_html + '<a class=\"w3-bar-item w3-button\" href=\"#' + analyse_name +'-' + f +'\">' + f + ' Distributions</a>\\n'\n        \n    sidebar_html = sidebar_html + '</nav>\\\n    <!-- Overlay effect when opening sidebar on small screens -->\\\n<div class=\"w3-overlay w3-hide-large\" onclick=\"w3_close()\" style=\"cursor:pointer\" title=\"close side menu\" id=\"myOverlay\"></div>'\n    return(sidebar_html)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Read Files"}, {"metadata": {}, "cell_type": "markdown", "source": "## Load Functions"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## read in sample annotation files \n## and check compulsory fields and field values\n## INPUT: path-to-file\n## OUTPUT: table t\ndef read_sample_annot(file, deli):#, field_std_names, field_std_values):\n    t = hl.import_table(file, impute=True, delimiter=deli)\n    # get table fields\n    col_dict = get_table_fields(t)\n    # check mandatory fields\n    if 'Sample' not in list(col_dict.keys()):\n        sys.exit('Sample does not exist!')\n    t= t.key_by('Sample')\n    \n    if 'isCase' in list(col_dict.keys()):\n        if col_dict['isCase'] != 'bool':\n            sys.exit('isCase is not bool')\n    else:\n        sys.exit('isCase does not exist!')\n    \n    t = t.annotate(CaseControl = hl.cond(t.isCase, 'Case', 'Control'))\n        \n    # check other optional fields\n    if 'isFemale' in list(col_dict.keys()):\n        if col_dict['isFemale'] != 'bool':\n            sys.exit('isFemale is not bool!')\n    else:\n        sys.exit('isFemale does not exist!')\n    t = t.annotate(Gender = hl.cond(t.isFemale,'Female', 'Male'))\n    \n    return(t)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def read_metadata(metadata, merge_type, file_type):\n    mts = []    \n    ## read in files\n    if file_type == 'plink':\n        for file in metadata:\n            print('plink file: ' + file)\n            mt_name = file + '.mt'\n            hl.import_plink(bed= file + '.bed', bim = file + '.bim', fam = file + '.fam',skip_invalid_loci=True, min_partitions=int(numPartitions)).write(mt_name,overwrite=True)\n            mts.append(hl.read_matrix_table(mt_name))\n    elif file_type == 'vcf':\n        for file in metadata:\n            print('vcf file: ' + file)\n            mt_name = re.sub(r'vcf(\\.bgz)$','mt', file )\n            hl.import_vcf(path=file,skip_invalid_loci=True, min_partitions=int(numPartitions)).write(mt_name,overwrite=True)\n            mts.append(hl.read_matrix_table(mt_name))\n    else:\n        sys.exit('Metadata file type not provided or supported!')\n    \n    ## merge files\n    if merge_type == 'variant':\n        mt = hl.MatrixTable.union_rows(*mts)\n    elif merge_type == 'sample':\n        mt = mts[0]\n        for cur_mt in mts[1:]:\n            mt = mt.union_cols(cur_mt)\n    \n    return(mt, mts)\n    ", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## combine sample annotation table to the matrix table\n## INPUT: t(table) ,mt(MatrixTable)\n## OUTPUT: matrixtable with t joined to the cols\ndef join_rows_cols(t, mt):\n    # get id info of two tables\n    id_list_annot = [ re.sub('^(.*=)\\'(.*)\\'(.*)$','\\\\2', str(w) ) for w in t.select().collect()]\n    id_list_mt = [ re.sub('^(.*=)\\'(.*)\\'(.*)$','\\\\2', str(w) ) for w in mt.cols().key_by('s').select().collect()]\n   \n    # compare id info\n    isSubset = all(elem in id_list_annot  for elem in id_list_mt)\n    if not isSubset:\n        sys.exit('Sample annotations missing!')\n    # join mt\n    mt = mt.annotate_cols(pheno = t[mt.s])\n    # break multiallelic\n    mt = hl.split_multi_hts(mt)\n    ## get variant_qc and sample_qc\n    mt = hl.variant_qc(mt)\n    mt = hl.sample_qc(mt)\n    # remove duplicates\n    mt = mt.distinct_by_row()\n    mt = mt.distinct_by_col()\n    return(mt)\n        ", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def print_init_summary_html(sample_annot, metadata, mt, mts):#, field_std_names, field_std_values):\n    \n    summary_html = '<p> ' + '<b>Annotation File: </b>' \n    summary_html = summary_html + '<ul style=\"list-style-type: disc;\">\\n'\n    ## for each annotation file\n    for file in sample_annot:\n        summary_html = summary_html + '<li>' + file + '</li>\\n'\n    summary_html = summary_html + '</ul>\\n' + '<b>VCF file: </b>' + '<ul style=\"list-style-type: disc;\">\\n'    \n    for file in metadata:\n        summary_html = summary_html + '<li>' + file + '</li>\\n'\n    summary_html = summary_html + '</ul>\\n' \n    \n    for i in range(0,len(metadata)):\n        summary_html = summary_html + '<b>metadata filename: </b>' + metadata[i] + '<br>\\n'\n        summary_html = summary_html + '<b># samples: </b>' + str(mts[i].count_cols()) + '<br>\\n'\n        summary_html = summary_html + '<b># variants: </b>' + str(mts[i].count_rows()) + '<br>\\n'\n        summary_html = summary_html + '<b>Call rate: </b>' + str(mt.count_rows()/mts[i].count_rows()) + '<br>'\n    summary_html = summary_html + '<b><i>After joining sample annotations and vcf files....</i></b><br>'\n    summary_html = summary_html + '<b>Total # of Sample analysed: </b>' + str(mt.count_cols()) + '<br>'\n    summary_html = summary_html + '<b>Total # of Variant analysed: </b>' + str(mt.count_rows()) + '<br>'\n    \n    summary_html = summary_html + '</p>'\n    \n    ## save file\n    # write into html file\n    filepath = \"htmls/summary.html\"\n    directory = os.path.dirname(filepath)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    f = open(filepath, \"w+\")\n    f.write(summary_html)\n    f.close()\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def print_saved_summary_html(mt,mt_name):\n    # read saved mt\n    \n    summary_html = '<p> '\n    summary_html = summary_html + '<b>MatrixTable File: </b>' + mt_name + '<br>'\n    summary_html = summary_html + '<b># of Sample analysed: </b>' + str(mt.count_cols()) + '<br>'\n    summary_html = summary_html + '<b># of Variants analysed: </b>'+ str(mt.count_rows()) + '<br>'\n   \n    summary_html = summary_html + '</p>'\n    \n    ## save file\n    # write into html file\n    filepath = \"htmls/summary.html\"\n    directory = os.path.dirname(filepath)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    \n    f = open(filepath, \"w+\")\n    f.write(summary_html)\n    f.close()\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "\nif sample_annot_file_list and mt_file_list :\n    # read in files\n    t = read_sample_annot(sample_annot_file_list, sample_annot_deli)\n    mt, mts = read_metadata(mt_file_list, mt_merge_type, mt_file_type)\n    mt = join_rows_cols(t, mt)\n    # create result directory and change directory\n    shutil.copytree('templates', result_dir)\n    os.chdir(result_dir)\n    # print out summary result\n    print_init_summary_html(sample_annot_file_list, mt_file_list, mt, mts)\nelif mt_name in globals():\n    # read saved mt\n    mt = hl.read_matrix_table(mt_name)\n    # create result directory and change directory\n    shutil.copytree('templates', result_dir)\n    os.chdir(result_dir)\n    # print out summary result\n    print_saved_summary_html(mt, mt_name)\n    ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Input file infos and read files (2 options)"}, {"metadata": {}, "cell_type": "markdown", "source": "### read from sample annotation files and vcf files\n#### sample annotations:\ntab-delimited\nheader needed\ncompulsory fields: SampleID and isCase (bool)\noptional fields (analyse if exist): isFemale/isMale, Population, SuperPopulation\nfield names must be the same as above in the header\n#### vcf:\n-standard vcf format (can be bgz or not)"}, {"metadata": {}, "cell_type": "markdown", "source": "# Sample Annotation Data Analysis"}, {"metadata": {}, "cell_type": "markdown", "source": "## Load Functions"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def get_sample_annot_info(mt, downsample_percent, graph_type, preset_fields):\n    analyse_name = 'Sample Annotations'\n    plot_html = {}\n    for f in preset_fields:\n        plot_html[f] = '<div>\\\n        <h2 id=\"' + f +'\" class=\"w3-text-teal\">' + f + '</h2>\\n'\n    isVariant = False\n    col_dict = get_table_fields(mt.cols().select('pheno').key_by('pheno').select().flatten())\n    \n    cat_fields = {}\n    fns = {}    \n    for k in list(col_dict.keys()):\n        field_names = k.split('.')\n        print(field_names)\n        if len(field_names) == 2:\n            field = mt[field_names[0]][field_names[1]]\n            field_name = field_names[1]\n            fns[k] = field_name\n        else:\n            print('error too many field depth')\n            break\n        if field_name not in preset_fields:\n            print('Found non-preset fields: ' + field_name)\n            continue\n        \n        \n        \n        cat_fields[k] = isCat(mt, field, isVariant)\n        if re.match(r'.*int.*',col_dict[k], re.M) or re.match(r'.*float.*',col_dict[k],re.M) and not isCat(mt, field, isVariant):\n            # numbers -> histgram\n            plot_html[field_name] = plot_html[field_name] + get_hist_graph(mt,field,field_name,downsample_percent,isVariant, analyse_name)\n        else:\n            # catogorical values and non-float types get bar_graphs\n            plot_html[field_name] = plot_html[field_name]  + get_bar_graph(mt, field, field_name, isVariant, analyse_name)\n    \n    #get combined graphs\n    for f in cat_fields.keys():\n        for f2 in cat_fields.keys():\n            if cat_fields[f2] == True and f != f2:\n                print('f:' + f + ' f2: ' + f2)\n                plot_html[fns[f]] = plot_html[fns[f]] + get_bar_graph_A_by_B(mt,[f,f2],graph_type, analyse_name)\n    plot_html_all = ''\n    plot_html_all = create_side_bar(preset_fields, analyse_name)\n    plot_html_all = plot_html_all + '<!-- Main content: shift it to the right by 250 pixels when the sidebar is visible -->\\\n<div class=\"w3-main\" style=\"margin-left:250px\">\\\n  <div class=\"w3-row w3-padding-64\">\\\n    <div class=\"w3-container\">\\\n      <h1 id=\"sa\" class=\"w3-text-teal\">Analysis of Sample annotations data</h1>\\\n      <p>some description if you want</p>\\n'\n\n    for s in preset_fields:\n        plot_html_all = plot_html_all + plot_html[s] + '</div>'\n    plot_html_all = plot_html_all + '</div>\\n</div>\\n</div>\\n'\n    return(plot_html_all)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Conduct Analysis"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "if 'isCase' in fields_to_plot:\n    fields_to_plot.remove('isCase')\n    fields_to_plot.append('CaseControl')\nif 'isFemale' in fields_to_plot:\n    fields_to_plot.remove('isFemale')\n    fields_to_plot.append('Gender')", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "plot_html = get_sample_annot_info(mt,downsample_percent,graph_type, fields_to_plot)\n    \n# write into html file\nfilepath = \"htmls/sample_annot.html\"\nf = open(filepath, \"w+\")\nf.write(plot_html)\nf.close()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# QC analysis"}, {"metadata": {}, "cell_type": "markdown", "source": "## Load functions"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## given a matrixTable\n## plot all plots for each field in sample_qc and variant_qc\n## INPUT: matrixTable, isVaraiant(boolean), downsample_percent, analyse_name\n## OUTPUT: list of plots\ndef get_qc_info(mt, isVariant, downsample_percent, analyse_name):\n\n    plot_html = '<!-- Main content: shift it to the right by 250 pixels when the sidebar is visible -->\\\n<div class=\"w3-main\" style=\"margin-left:250px\">\\\n  <div class=\"w3-row w3-padding-64\">\\\n    <div class=\"w3-container\">\\\n      <h1 id=\"sa\" class=\"w3-text-teal\">Per '+ analyse_name +' analysis</h1>\\\n      <p>some description if you want</p>\\n'\n    if isVariant:\n        col_dict = get_table_fields(mt.rows().select('variant_qc').key_by('variant_qc').select().flatten())\n    else:\n        col_dict = get_table_fields(mt.cols().select('sample_qc').key_by('sample_qc').select().flatten())\n    \n    sidebar_field_list = []\n    for k in list(col_dict.keys()):\n        field_names = k.split('.')\n        if len(field_names) == 2:\n            field = mt[field_names[0]][field_names[1]]\n            field_name = field_names[1]\n        elif len(field_names) == 3:\n            continue\n            field = mt[field_names[0]][field_names[1]][field_names[2]]\n            field_name = field_names[2]\n        else:\n            print('error too many field depth')\n            break\n\n        if re.match(r'.*int.*',col_dict[k], re.M) or re.match(r'.*float.*',col_dict[k],re.M):\n            # numbers -> histgram\n            if re.match(r'^array',col_dict[k],re.M):\n                for i in range(0,2):\n                    if i == 0:\n                        field_name_x = field_name + '_ref_allele' \n                    else:\n                        field_name_x = field_name + '_alt_allele'\n                    sidebar_field_list.append(field_name_x)\n                    plot_html = plot_html + get_hist_graph(mt, field[i],field_name_x,downsample_percent,isVariant, analyse_name)\n            else:\n                print(field_name)\n                sidebar_field_list.append(field_name)\n                plot_html = plot_html + get_hist_graph(mt, field,field_name,downsample_percent,isVariant, analyse_name)\n        else:\n            continue\n    \n    sidebar_html = create_side_bar(sidebar_field_list, analyse_name)\n    plot_html = sidebar_html + plot_html + '</div>\\n</div>\\n'\n    \n    return(plot_html)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Conduct variant QC analysis"}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "plot_html = get_qc_info(mt, True, downsample_percent, 'Variant QC')\n    \n# write into html file\nfilepath = \"htmls/variant_qc.html\"\nf = open(filepath, \"w+\")\nf.write(plot_html)\nf.close()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Conduct sample QC analysis"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#plot_html = get_qc_info(mt, False, downsample_percent, 'Sample QC')\nplot_html = get_qc_info(mt, False, 1, 'Sample QC')\n\n# write into html file\nfilepath = \"htmls/sample_qc.html\"\nf = open(filepath, \"w+\")\nf.write(plot_html)\nf.close()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Principle Component Analysis (PCA)"}, {"metadata": {}, "cell_type": "markdown", "source": "## Load functions"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def get_PCA_scatter(x,y,label,title=None, xlabel=None, ylabel=None, collect_all=False, n_divisions=500, size=4):\n\n    palette = d3['Category10'][10]\n    \n    # enlist data from expression\n    if collect_all:\n        res = hl.tuple([x, y, label]).collect()\n        label = [point[2] for point in res]\n    else:\n        agg_f = x._aggregation_method()\n        res = agg_f(hl.agg.downsample(x, y, label=label, n_divisions=n_divisions))\n        label = [point[2][0] for point in res]\n\n    x = [point[0] for point in res]\n    y = [point[1] for point in res]\n    \n    p = figure(title=title, x_axis_label=xlabel, y_axis_label=ylabel, tooltips = '@label', background_fill_color='#EEEEEE')\n    factors = list(set(label))\n    fields = dict(x=x, y=y, label=label)\n    source = ColumnDataSource(fields)\n    if len(factors) > len(palette):\n        color_gen = cycle(palette)\n        colors = []\n        for i in range(0, len(factors)):\n            colors.append(next(color_gen))\n    else:\n        colors = palette[0:len(factors)]\n\n    color_mapper = CategoricalColorMapper(factors=factors, palette=colors)\n    p.circle('x', 'y', alpha=0.5, source=source,size=size, color={'field': 'label', 'transform': color_mapper}, legend='label')\n    #show(p)\n    return(p)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## Principle Component Analysis\n## INPUT: mt(matrixTable), number of factors(int)\n## OUTPUT: annotated mt, plot_html\ndef get_PCA_graph(mt, n_factor, field_list):\n    analyse_name = 'PCA'\n    plot_html = create_side_bar(['CaseControl'] + field_list, analyse_name)\n    plot_html = plot_html + '<div class=\"w3-main\" style=\"margin-left:250px\">\\\n  <div class=\"w3-row w3-padding-64\">\\\n    <div class=\"w3-container\">\\\n      <h1 id=\"vqc\" class=\"w3-text-teal\">PCA Analysis</h1>\\\n      <p>PCA analysis of factor '+ str(n_factor) + ' </p>'\n    eigenvalues, pcs, loadings = hl.hwe_normalized_pca(mt.GT, k=n_factor)\n    print('Done PCA analysis')\n    \n    ## plot pcs per sample\n    mt = mt.annotate_cols(pcs = pcs[mt.s].scores)\n    ## plot all pcs for case/control\n    for i in range(0,n_factor):\n        j = i+1\n        while j < n_factor:\n            print('Starting plotting PC'+ str(i) + ' vs PC' + str(j))\n            x = 'PC' + str(i+1)\n            y = 'PC' + str(j+1)\n            title =  y + ' vs ' +  x \n            title = 'CaseControl PCA - ' + y + ' vs ' +  x \n            if i == 0 and j == 1:\n                id_link = analyse_name + '-' + 'CaseControl'\n            else:\n                id_link = 'pca-cc-'+str(i)+str(j)\n            \n            p = get_PCA_scatter(mt.pcs[i],\n                            mt.pcs[j],\n                            label=mt.pheno.CaseControl,\n                            title=title, xlabel=x, ylabel=y)\n            plot_html = plot_html + save_plot(p,title,analyse_name,id_link)\n            j = j + 1\n            \n    ## plot 1&2 for others \n    col_dict = get_table_fields(mt.cols().select('pheno').key_by('pheno').select().flatten())\n    for f in list(col_dict.keys()):\n        field_names = f.split('.')\n        if len(field_names) == 2:\n            field_name = field_names[1]\n        if field_name in field_list:\n            title = field_name + ' PCA - PC2 vs PC1'\n            id_link = analyse_name + '-' + field_name\n            p = get_PCA_scatter(mt.pcs[0],\n                            mt.pcs[1],\n                            label=mt[field_names[0]][field_names[1]],\n                            title=title, xlabel='PC1', ylabel='PC2')\n            plot_html = plot_html + save_plot(p,title,analyse_name,id_link)\n    plot_html = plot_html + '</div>\\n</div>'        \n    \n    return(mt, plot_html)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Conduct analysis"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "if 'CaseControl' in fields_to_plot:\n    fields_to_plot.remove('CaseControl')", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "mt, plot_html = get_PCA_graph(mt, n_factor, fields_to_plot)\n# write into html file\nfilepath = \"htmls/pca.html\"\nf = open(filepath, \"w+\")\nf.write(plot_html)\nf.close()\n    ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Logistic Regression and Manhattan Plot (must after PCA)"}, {"metadata": {}, "cell_type": "markdown", "source": "## Load functions"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def get_manhattan_graph(mt,method, n_divisions=500):\n    title = 'Manhattan plot (' + method +')'\n    id_link = 'Logistic Regression-'+method\n    field_name = 'logreg_' + method\n    # plotting\n    hover_fields = {'rsid': mt.rsid,\n                'locus': mt.locus,\n                'p_value': mt[field_name]['p_value']}\n    p = hl.plot.manhattan(pvals=mt[field_name]['p_value'], hover_fields=hover_fields, title=title, n_divisions=n_divisions)\n\n    return(save_plot(p, title,'Logistic Regression', id_link))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def get_qq_graph(mt,method, n_divisions=500 ):\n    title = 'Q-Q plot (' + method +')'\n    id_link = 'lgqq-'+method\n    field_name = 'logreg_' + method\n    # plotting\n    p = hl.plot.qq(pvals=mt[field_name]['p_value'], n_divisions = n_divisions)\n    return(save_plot(p, title,'Logistic Regression', id_link))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def logistic_regression (mt, method, n_factor):\n    # logistic regression\n    covariates = [mt.pcs[i] for i in range(0,n_factor)]\n    if 'pheno.isFemale' in list(get_table_fields(mt.cols().select('pheno').flatten()).keys()):\n        covariates.append(mt.pheno.isFemale)\n\n    result = hl.logistic_regression_rows(test =method, \n                                          y=mt.pheno.isCase,\n                                          x=mt.GT.n_alt_alleles(),\n                                          covariates=covariates)\n    # annotate matrixtable\n    field_name = 'logreg_' + method\n    mt = mt.annotate_rows( logreg = result[mt.locus, mt.alleles])\n    if field_name in mt._fields:\n        mt = mt.drop(mt[field_name])\n    mt = mt.rename({'logreg': field_name})\n    \n    return(mt)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Conduct analysis"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# wald\nmt = logistic_regression(mt, 'wald', n_factor)\nmt.count()\nplot_html_wald = get_manhattan_graph(mt, 'wald', 150)\nplot_html_wald = plot_html_wald + get_qq_graph(mt, 'wald', 150)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#score\nmt = logistic_regression(mt, 'score', n_factor)\nmt.count()\nplot_html_score = get_manhattan_graph(mt, 'score', 450)\nplot_html_score = plot_html_score + get_qq_graph(mt, 'score', 450)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#lrt\nmt = logistic_regression(mt, 'lrt', n_factor)\nmt.count()\nplot_html_lrt = get_manhattan_graph(mt, 'lrt', 150)\nplot_html_lrt = plot_html_lrt + get_qq_graph(mt, 'lrt', 150)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "plot_html = create_side_bar(['wald','score','lrt'],'Logistic Regression')\nplot_html = plot_html + '<div class=\"w3-main\" style=\"margin-left:250px\">\\\n    <div class=\"w3-row w3-padding-64\">\\\n    <div class=\"w3-container\">\\\n      <h1 id=\"vqc\" class=\"w3-text-teal\">Logistic Regression</h1>\\\n      <p>Manhattan Plots of p-values from Logistic Regressions(3 methods)</p>\\n'\nplot_html = plot_html + plot_html_wald + plot_html_score + plot_html_lrt + '</div>\\n</div>\\n'\n# write into html file\nfilepath = \"htmls/manhattan.html\"\nf = open(filepath, \"w+\")\nf.write(plot_html)\nf.close()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Variant-Spark Analysis"}, {"metadata": {}, "cell_type": "markdown", "source": "### export current LR-ed matrix and conduct variant-spark analysis"}, {"metadata": {}, "cell_type": "markdown", "source": "## Load Functions"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def vs_analysis(mt):\n\n    rf_model = vshl.random_forest_model(y=mt.pheno.isCase, x=mt.GT.n_alt_alleles(),\n                                        seed = 13, mtry_fraction = mtry_fraction,\n                                        min_node_size = min_node_size, max_depth = max_depth)\n    rf_model.fit_trees(num_of_tree, batch_size)\n    print(\"OOB: \", rf_model.oob_error())\n    impTable = rf_model.variable_importance()\n    \n    mt = mt.annotate_rows(vs_score = impTable[mt.locus, mt.alleles].importance)\n    \n    return(mt)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def get_vs_manhattan(mt):\n    mt = mt.annotate_rows(vs_stats = mt.aggregate_rows(hl.agg.stats(mt['vs_score'])))\n    mt = mt.annotate_rows(z_score = (mt['vs_score'] - mt.vs_stats.mean)/mt.vs_stats.stdev)\n    mt = mt.annotate_rows(vs_score_converted = 10** -mt.z_score)\n    title = 'Variant-Spark Manhattan plot'\n    id_link = 'man-vs'\n    folder = 'Variant Spark'\n    hover_fields = {'rsid': mt.rsid, 'vs_score': mt.vs_score}\n    p = hl.plot.manhattan(pvals=mt.vs_score_converted, hover_fields=hover_fields, title=title)\n    p.yaxis.axis_label = 'Z score of importantce score by VS'\n    return(save_plot(p, title, folder, id_link))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Conduct Analysis"}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "filename = re.sub(r'\\s', '_', analysis_name)\nfilepath = result_dir + '/output/variant-spark/' + filename\ndirectory = os.path.dirname(filepath)\nif not os.path.exists(directory):\n    os.makedirs(directory)\n\nmt = vs_analysis(mt)\nplot_html = get_vs_manhattan(mt)\n\n# write into html file\nfilepath = \"htmls/variant-spark.html\"\nf = open(filepath, \"w+\")\nf.write(plot_html)\nf.close()\n    ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Save Results"}, {"metadata": {}, "cell_type": "markdown", "source": "## Copy Plots and HTML files to S3"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "cmd = 'aws s3 cp --recursive ' + result_dir + '/ ' + S3_Path + analysis_name + '/'\nprint(cmd)\nsubprocess.call(cmd, shell=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## export as a matrix table - ready to use for later analysis"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "file_name = 'annotated_' + re.sub(r'\\s', '_', analysis_name)\noutput_prefix = S3_Path + analysis_name + '/output/' + file_name\nprint(output_prefix)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "mt_name = output_prefix + '.mt'\nmt.write(mt_name,overwrite=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## export as vcf"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "output_path = output_prefix + '.vcf.bgz' # extension needed\nhl.export_vcf(mt, output_path) # 1 output file", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## export as plink"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "output_path = output_prefix # no extension needed\nhl.export_plink(mt, output_path) # 3 output files ", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}