{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Simple Notebook\n### This notebook is written using Hail v0.2 and VariantSpark."}, {"metadata": {}, "cell_type": "markdown", "source": "# User Block"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "#S3_Path='s3://YOUR_BUCKET_OR_PATH/ViGWAS/'\nS3_Path='s3://csiro-tb/notebooks/Hail2/ViGWAS/'\n\n## Some configs\nnumCPU = 256\nmemory = '60g'\nnumPartitions = numCPU*4", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Environment initialization"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "## Environment init\n\nimport os\nfrom pyspark import SparkContext\nsc = SparkContext()\n\nimport hail as hl\nimport varspark.hail as vshl\nvshl.init(sc=sc)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from bokeh.io import show, output_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource, FactorRange, LabelSet, Label\nfrom bokeh.transform import factor_cmap\nfrom bokeh.palettes import d3\nfrom bokeh.core.properties import value\nfrom bokeh.embed import file_html\nfrom bokeh.resources import CDN\nfrom bokeh.layouts import gridplot\nfrom bokeh.models.mappers import CategoricalColorMapper\n\nfrom pprint import pprint\noutput_notebook()\n\nimport re\nimport numpy as np\nimport math as math\nimport sys\nimport operator\nfrom collections import OrderedDict\nimport subprocess\nfrom itertools import cycle\nimport shutil", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Load VCF files"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "mt = hl.import_vcf(path=S3_Path+'sample_input/V1.vcf.bgz',\n                   skip_invalid_loci=True,\n                   min_partitions=int(numPartitions))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Sample Annotation Data Analysis"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "Annot = hl.import_table(S3_Path+'sample_input/hipster.csv',\n                        impute=True, delimiter=',').key_by('Sample')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Annotate dataset with sample annotation"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "mt = mt.annotate_cols(pheno = Annot[mt.s])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# PCA analysis"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "eigenvalues, pcs, loadings = hl.hwe_normalized_pca(mt.GT, k=2)\nmt = mt.annotate_cols(pcs = pcs[mt.s].scores)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "p = hl.plot.scatter(pcs.scores[0], pcs.scores[1],\n                    label=mt.cols()[pcs.s].pheno.Hipster,\n                    title='PCA Case/Control', xlabel='PC1', ylabel='PC2', collect_all=True)\nshow(p)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Logistic Regression"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "covariates = [mt.pheno.isFemale, mt.pcs[0], mt.pcs[1]]\n\nresult = hl.logistic_regression_rows(test ='wald', \n                                          y=mt.pheno.isCase,\n                                          x=mt.GT.n_alt_alleles(),\n                                          covariates=covariates)\n\nmt = mt.annotate_rows( logreg = result[mt.locus, mt.alleles])", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "p = hl.plot.manhattan(result.p_value)\nshow(p)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Variant-Spark RandomForest"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rf_model = vshl.random_forest_model(y=mt.pheno.isCase, x=mt.GT.n_alt_alleles(),\n                                    seed = 13, mtry_fraction = 0.1,\n                                    min_node_size = 10, max_depth = 15)\n\nrf_model.fit_trees(n_trees=100, batch_size=25)\n\nprint(\"OOB: \", rf_model.oob_error())\nimpTable = rf_model.variable_importance()\n\nmt = mt.annotate_rows(vs_score = impTable[mt.locus, mt.alleles].importance)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "mt = mt.annotate_rows(vs_stats = mt.aggregate_rows(hl.agg.stats(mt['vs_score'])))\nmt = mt.annotate_rows(z_score = (mt['vs_score'] - mt.vs_stats.mean)/mt.vs_stats.stdev)\nmt = mt.annotate_rows(vs_score_converted = 10** -mt.z_score)\ntitle = 'Variant-Spark Manhattan plot'\nid_link = 'man-vs'\nfolder = 'Variant Spark'\nhover_fields = {'rsid': mt.rsid, 'vs_score': mt.vs_score}\np = hl.plot.manhattan(pvals=mt.vs_score_converted, hover_fields=hover_fields, title=title)\np.yaxis.axis_label = 'Z score of importantce score by VS'\nshow(p)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Describe matrix Table"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "mt.describe()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Write MT to S3"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "mt.write(S3_Path+'my_dataset.mt',overwrite=True)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}